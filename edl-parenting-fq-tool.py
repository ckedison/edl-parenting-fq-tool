import streamlit as st
import google.generativeai as genai
import pandas as pd
import json
import re

# App è¨­å®š
st.set_page_config(page_title="Qforia", layout="wide")

# éš±è— Streamlit çš„é è¨­é¸å–®å’Œé é¦–å·¥å…·åˆ—
hide_streamlit_style = """
            <style>
            #MainMenu {visibility: hidden;}
            header {visibility: hidden;}
            </style>
            """
st.markdown(hide_streamlit_style, unsafe_allow_html=True)

st.title("ğŸ” FQæŸ¥è©¢æ“´å±•æ¨¡æ“¬å™¨-EDLxè¦ªå­å¤©ä¸‹")

# å´é‚Šæ¬„ï¼šAPI é‡‘é‘°è¼¸å…¥èˆ‡æŸ¥è©¢
st.sidebar.header("è¨­å®š")
gemini_key = st.sidebar.text_input("Gemini API é‡‘é‘°", type="password")
user_query = st.sidebar.text_area("è¼¸å…¥æ‚¨çš„æŸ¥è©¢", "å“ªæ¬¾é›»å‹• SUV æœ€é©åˆé–‹ä¸Šé›·å°¼çˆ¾å±±ï¼Ÿ", height=120)
mode = st.sidebar.radio("æœå°‹æ¨¡å¼", ["AI ç¸½è¦½ (ç°¡æ˜“)", "AI æ¨¡å¼ (è¤‡é›œ)"])

# ç‰ˆæ¬Šè²æ˜
st.sidebar.markdown("---")
st.sidebar.caption("æ­¤å·¥å…·ç‚ºã€ŒEDLæˆæ¬Šçµ¦è¦ªå­å¤©ä¸‹é›†åœ˜ä½¿ç”¨ï¼Œæˆæ¬Šæ™‚é–“è‡³2025å¹´ã€")


# è¨­å®š Gemini
if gemini_key:
    genai.configure(api_key=gemini_key)
    # ç¢ºä¿æ‚¨ä½¿ç”¨çš„æ¨¡å‹èƒ½è‰¯å¥½æ”¯æ´è¼ƒé•·/è¤‡é›œçš„ JSON è¼¸å‡ºã€‚
    # ä½¿ç”¨è€…æ¨¡å‹ "gemini-2.5-flash-preview-05-20" å¯èƒ½æ˜¯ä¸€å€‹ç‰¹å®šç‰ˆæœ¬ï¼›
    # å¦‚æœå‡ºç¾å•é¡Œï¼Œå¯ä»¥è€ƒæ…®å˜—è©¦ "gemini-1.5-flash-latest" æˆ– "gemini-1.5-pro-latest"ã€‚
    model = genai.GenerativeModel("gemini-1.5-flash-latest") # ä½¿ç”¨ä¸€å€‹å¸¸è¦‹çš„æœ€æ–° flash æ¨¡å‹
else:
    st.error("è«‹è¼¸å…¥æ‚¨çš„ Gemini API é‡‘é‘°ä»¥ç¹¼çºŒã€‚")
    st.stop()

# åŒ…å«è©³ç´°æ€ç¶­éˆ (Chain-of-Thought) é‚è¼¯çš„æç¤º
def QUERY_FANOUT_PROMPT(q, mode):
    min_queries_simple = 10
    min_queries_complex = 20

    # æ ¹æ“šæ¨¡å¼é¸æ“‡ä¸åŒçš„æŸ¥è©¢æ•¸é‡èªªæ˜
    if mode == "AI ç¸½è¦½ (ç°¡æ˜“)":
        num_queries_instruction = (
            f"é¦–å…ˆï¼Œåˆ†æä½¿ç”¨è€…æŸ¥è©¢ï¼šã€Œ{q}ã€ã€‚æ ¹æ“šå…¶è¤‡é›œåº¦å’Œã€Œ{mode}ã€æ¨¡å¼ï¼Œ"
            f"**ä½ å¿…é ˆæ±ºå®šä¸€å€‹æœ€ä½³çš„æŸ¥è©¢ç”Ÿæˆæ•¸é‡ã€‚** "
            f"é€™å€‹æ•¸é‡å¿…é ˆ **è‡³å°‘ç‚º {min_queries_simple}**ã€‚ "
            f"å°æ–¼ä¸€å€‹ç›´æ¥çš„æŸ¥è©¢ï¼Œç”Ÿæˆå¤§ç´„ {min_queries_simple}-{min_queries_simple + 2} å€‹æŸ¥è©¢å¯èƒ½å°±è¶³å¤ äº†ã€‚"
            f"å¦‚æœæŸ¥è©¢æœ‰å¹¾å€‹ä¸åŒçš„æ–¹é¢æˆ–å¸¸è¦‹çš„å¾ŒçºŒå•é¡Œï¼Œç›®æ¨™å¯ä»¥è¨­å®šåœ¨ç¨é«˜çš„æ•¸é‡ï¼Œä¾‹å¦‚ {min_queries_simple + 3}-{min_queries_simple + 5} å€‹æŸ¥è©¢ã€‚"
            f"è«‹ç°¡è¦èªªæ˜ä½ ç‚ºä½•é¸æ“‡é€™å€‹ç‰¹å®šçš„æŸ¥è©¢æ•¸é‡ã€‚æŸ¥è©¢æœ¬èº«æ‡‰è©²ç¯„åœæ˜ç¢ºä¸”é«˜åº¦ç›¸é—œã€‚"
        )
    else:  # AI æ¨¡å¼ (è¤‡é›œ)
        num_queries_instruction = (
            f"é¦–å…ˆï¼Œåˆ†æä½¿ç”¨è€…æŸ¥è©¢ï¼šã€Œ{q}ã€ã€‚æ ¹æ“šå…¶è¤‡é›œåº¦å’Œã€Œ{mode}ã€æ¨¡å¼ï¼Œ"
            f"**ä½ å¿…é ˆæ±ºå®šä¸€å€‹æœ€ä½³çš„æŸ¥è©¢ç”Ÿæˆæ•¸é‡ã€‚** "
            f"é€™å€‹æ•¸é‡å¿…é ˆ **è‡³å°‘ç‚º {min_queries_complex}**ã€‚ "
            f"å°æ–¼éœ€è¦æ¢ç´¢ä¸åŒè§’åº¦ã€å­ä¸»é¡Œã€æ¯”è¼ƒæˆ–æ›´æ·±å±¤å«ç¾©çš„å¤šé¢å‘æŸ¥è©¢ï¼Œ"
            f"ä½ æ‡‰è©²ç”Ÿæˆä¸€å¥—æ›´å…¨é¢çš„æŸ¥è©¢ï¼Œå¯èƒ½åœ¨ {min_queries_complex + 5}-{min_queries_complex + 10} å€‹ä¹‹é–“ï¼Œå¦‚æœæŸ¥è©¢ç‰¹åˆ¥å»£æ³›æˆ–æ·±å…¥ï¼Œç”šè‡³å¯ä»¥æ›´å¤šã€‚"
            f"è«‹ç°¡è¦èªªæ˜ä½ ç‚ºä½•é¸æ“‡é€™å€‹ç‰¹å®šçš„æŸ¥è©¢æ•¸é‡ã€‚æŸ¥è©¢æ‡‰è©²å¤šæ¨£åŒ–ä¸”æ·±å…¥ã€‚"
        )

    return (
        f"You are simulating Google's AI Mode query fan-out process for generative search systems.\n"
        f"The user's original query is: \"{q}\". The selected mode is: \"{mode}\".\n\n"
        f"**Your first task is to determine the total number of queries to generate and the reasoning for this number, based on the instructions below:**\n"
        f"{num_queries_instruction}\n\n"
        f"**Once you have decided on the number and the reasoning, generate exactly that many unique synthetic queries.**\n"
        "Each of the following query transformation types MUST be represented at least once in the generated set, if the total number of queries you decide to generate allows for it (e.g., if you generate 12 queries, try to include all 6 types at least once, and then add more of the relevant types):\n"
        "1. Reformulations\n2. Related Queries\n3. Implicit Queries\n4. Comparative Queries\n5. Entity Expansions\n6. Personalized Queries\n\n"
        "The 'reasoning' field for each *individual query* should explain why that specific query was generated in relation to the original query, its type, and the overall user intent.\n"
        "Do NOT include queries dependent on real-time user history or geolocation.\n\n"
        "**IMPORTANT LANGUAGE REQUIREMENT: All generated 'query', 'user_intent', and 'reasoning' values inside the 'expanded_queries' array MUST be in Traditional Chinese (Taiwan).**\n\n"
        "Return only a valid JSON object. The JSON object should strictly follow this format:\n"
        "{\n"
        "  \"generation_details\": {\n"
        "    \"target_query_count\": 12, // This is an EXAMPLE number; you will DETERMINE the actual number based on your analysis.\n"
        "    \"reasoning_for_count\": \"The user query was moderately complex, so I chose to generate slightly more than the minimum for a simple overview to cover key aspects like X, Y, and Z.\" // This is an EXAMPLE reasoning; provide your own.\n"
        "  },\n"
        "  \"expanded_queries\": [\n"
        "    // Array of query objects. The length of this array MUST match your 'target_query_count'.\n"
        "    {\n"
        "      \"query\": \"Example query 1...\",\n"
        "      \"type\": \"reformulation\",\n"
        "      \"user_intent\": \"Example intent...\",\n"
        "      \"reasoning\": \"Example reasoning for this specific query...\"\n"
        "    },\n"
        "    // ... more query objects ...\n"
        "  ]\n"
        "}"
    )

# æŸ¥è©¢æ“´å±•ç”Ÿæˆå‡½æ•¸
def generate_fanout(query, mode):
    prompt = QUERY_FANOUT_PROMPT(query, mode)
    try:
        response = model.generate_content(prompt)
        json_text = response.text.strip()
        
        # æ¸…ç†æ½›åœ¨çš„ markdown ç¨‹å¼ç¢¼å€å¡Šæ¨™è¨˜
        if json_text.startswith("```json"):
            json_text = json_text[7:]
        if json_text.endswith("```"):
            json_text = json_text[:-3]
        json_text = json_text.strip()

        data = json.loads(json_text)
        generation_details = data.get("generation_details", {})
        expanded_queries = data.get("expanded_queries", [])

        # å„²å­˜è©³ç´°è³‡è¨Šä»¥ä¾›é¡¯ç¤º
        st.session_state.generation_details = generation_details

        return expanded_queries
    except json.JSONDecodeError as e:
        st.error(f"ğŸ”´ è§£æ Gemini å›æ‡‰çš„ JSON å¤±æ•—ï¼š{e}")
        st.text("å°è‡´éŒ¯èª¤çš„åŸå§‹å›æ‡‰ï¼š")
        st.text(json_text if 'json_text' in locals() else "ç„¡ (åœ¨ json_text æŒ‡æ´¾å‰ç™¼ç”ŸéŒ¯èª¤)")
        st.session_state.generation_details = None
        return None
    except Exception as e:
        st.error(f"ğŸ”´ ç”¢ç”Ÿéç¨‹ä¸­ç™¼ç”Ÿæœªé æœŸçš„éŒ¯èª¤ï¼š{e}")
        if hasattr(response, 'text'):
             st.text("åŸå§‹å›æ‡‰å…§å®¹ (è‹¥æœ‰)ï¼š")
             st.text(response.text)
        st.session_state.generation_details = None
        return None

# å¦‚æœ session_state ä¸­ä¸å­˜åœ¨ generation_detailsï¼Œå‰‡é€²è¡Œåˆå§‹åŒ–
if 'generation_details' not in st.session_state:
    st.session_state.generation_details = None

# ç”¢ç”Ÿä¸¦é¡¯ç¤ºçµæœ
if st.sidebar.button("åŸ·è¡ŒæŸ¥è©¢æ“´å±• ğŸš€"):
    # æ¸…é™¤å…ˆå‰çš„è©³ç´°è³‡è¨Š
    st.session_state.generation_details = None
    
    if not user_query.strip():
        st.warning("âš ï¸ è«‹è¼¸å…¥æŸ¥è©¢å…§å®¹ã€‚")
    else:
        with st.spinner("ğŸ¤– æ­£åœ¨ä½¿ç”¨ Gemini ç”¢ç”ŸæŸ¥è©¢æ“´å±•... è«‹ç¨å€™..."):
            results = generate_fanout(user_query, mode)

        if results: # æª¢æŸ¥ results æ˜¯å¦ä¸ç‚º None ä¸”ä¸ç‚ºç©º
            st.success("âœ… æŸ¥è©¢æ“´å±•å®Œæˆï¼")

            # å¦‚æœæœ‰å¯ç”¨çš„ç”Ÿæˆè¨ˆæ•¸ç†ç”±ï¼Œå‰‡é¡¯ç¤º
            if st.session_state.generation_details:
                details = st.session_state.generation_details
                generated_count = len(results)
                target_count_model = details.get('target_query_count', 'N/A')
                reasoning_model = details.get('reasoning_for_count', 'æ¨¡å‹æœªæä¾›ã€‚')

                st.markdown("---")
                st.subheader("ğŸ§  æ¨¡å‹çš„æŸ¥è©¢ç”Ÿæˆè¨ˆç•«")
                st.markdown(f"ğŸ”¹ **æ¨¡å‹æ±ºå®šçš„ç›®æ¨™æŸ¥è©¢æ•¸é‡ï¼š** `{target_count_model}`")
                st.markdown(f"ğŸ”¹ **æ¨¡å‹çš„æ•¸é‡æ±ºç­–ç†ç”±ï¼š** _{reasoning_model}_")
                st.markdown(f"ğŸ”¹ **å¯¦éš›ç”¢ç”Ÿçš„æŸ¥è©¢æ•¸é‡ï¼š** `{generated_count}`")
                st.markdown("---")
                
                if isinstance(target_count_model, int) and target_count_model != generated_count:
                    st.warning(f"âš ï¸ æ³¨æ„ï¼šæ¨¡å‹ç›®æ¨™ç”¢ç”Ÿ {target_count_model} å€‹æŸ¥è©¢ï¼Œä½†å¯¦éš›ç”¢ç”Ÿäº† {generated_count} å€‹ã€‚")
            else:
                st.info("â„¹ï¸ æ¨¡å‹çš„æ—¥æ‡‰ä¸­æœªåŒ…å«ç”Ÿæˆç´°ç¯€ (ç›®æ¨™æ•¸é‡ã€ç†ç”±)ã€‚")


            df = pd.DataFrame(results)
            # èª¿æ•´æ¬„ä½åç¨±ç‚ºä¸­æ–‡ä»¥åˆ©é¡¯ç¤ºï¼Œä½†ä¿æŒåŸå§‹æ¬„ä½åç¨±åœ¨ DataFrame ä¸­
            display_df = df.rename(columns={
                "query": "æŸ¥è©¢èªå¥",
                "type": "é¡å‹",
                "user_intent": "ä½¿ç”¨è€…æ„åœ–",
                "reasoning": "ç”Ÿæˆç†ç”±"
            })
            st.dataframe(display_df, use_container_width=True, height=(min(len(df), 20) + 1) * 35 + 3) # å‹•æ…‹é«˜åº¦

            csv = df.to_csv(index=False).encode("utf-8")
            st.download_button("ğŸ“¥ ä¸‹è¼‰ CSV", data=csv, file_name="qforia_è¼¸å‡º.csv", mime="text/csv")
        
        elif results is None: # åœ¨ generate_fanout ä¸­ç™¼ç”ŸéŒ¯èª¤
            # éŒ¯èª¤è¨Šæ¯å·²ç”± generate_fanout é¡¯ç¤º
            pass
        else: # è™•ç†ç©ºçš„çµæœåˆ—è¡¨ (ç©ºåˆ—è¡¨ï¼Œé None)
            st.warning("âš ï¸ æœªç”¢ç”Ÿä»»ä½•æŸ¥è©¢ã€‚æ¨¡å‹å›å‚³äº†ç©ºåˆ—è¡¨ï¼Œæˆ–ç™¼ç”Ÿäº†å•é¡Œã€‚")
